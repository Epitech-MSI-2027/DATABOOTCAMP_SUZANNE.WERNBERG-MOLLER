{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195507eb",
   "metadata": {},
   "source": [
    "\n",
    "# Analyse de Campagne Marketing — Notebook Guide Pas-à-Pas\n",
    "\n",
    "**Objectifs pédagogiques :**\n",
    "1. Chiffrer l’efficacité des campagnes marketing (KPIs, segments).\n",
    "2. Comprendre et justifier une segmentation client (clustering + RFM).\n",
    "3. Construire un modèle de prédiction de la **réponse** (`Response`) à la campagne récente.\n",
    "4. Adapter la présentation aux enjeux métier (recommandations actionnables).\n",
    "\n",
    "**Outil :** Python + Jupyter Notebook — dépendances standard (pandas, numpy, scikit-learn, matplotlib).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3887bc",
   "metadata": {},
   "source": [
    "## 1. Setup & Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports de base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Affichage\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Chemin des données\n",
    "DATA_PATH = Path(\"/mnt/data/Camp_Market.csv\")\n",
    "\n",
    "# Chargement\n",
    "df = pd.read_csv(DATA_PATH, sep=None, engine=\"python\")\n",
    "print(df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fb84a",
   "metadata": {},
   "source": [
    "## 2. Structure des données (dtypes, valeurs manquantes, cardinalités)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d301115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape = df.shape\n",
    "dtypes = df.dtypes.astype(str).to_frame(\"dtype\")\n",
    "missing = df.isna().sum().to_frame(\"missing\")\n",
    "missing[\"missing_%\"] = (df.isna().mean()*100).round(2)\n",
    "cardinality = df.nunique().to_frame(\"n_unique\")\n",
    "\n",
    "summary = dtypes.join(missing).join(cardinality).sort_values(by=[\"missing_%\",\"n_unique\"], ascending=[False, False])\n",
    "summary.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96846637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Aperçu des 20 premières colonnes:\")\n",
    "summary.iloc[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35c414",
   "metadata": {},
   "source": [
    "## 3. Nettoyage minimal & conversions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56806849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copie de travail\n",
    "data = df.copy()\n",
    "\n",
    "# Harmoniser les noms de colonnes (éviter espaces).\n",
    "data.columns = [c.strip().replace(\" \", \"_\") for c in data.columns]\n",
    "\n",
    "# Conversion automatique de date si présente\n",
    "if \"Dt_Customer\" in data.columns:\n",
    "    data[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"], errors=\"coerce\", dayfirst=True)\n",
    "    \n",
    "# Conversion probable des colonnes binaires en int (AcceptedCmp*, Response)\n",
    "for c in data.columns:\n",
    "    if c.lower().startswith(\"acceptedcmp\") or c.lower()==\"response\":\n",
    "        data[c] = pd.to_numeric(data[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Aperçu post-nettoyage\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4e281",
   "metadata": {},
   "source": [
    "## 4. KPIs — Efficacité des campagnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accepted_cols = [c for c in data.columns if c.lower().startswith(\"acceptedcmp\")]\n",
    "response_col = \"Response\" if \"Response\" in data.columns else None\n",
    "\n",
    "kpi = {}\n",
    "kpi[\"n_clients\"] = len(data)\n",
    "\n",
    "# Revenus/valeur client (si Mnt* présents)\n",
    "mnt_cols = [c for c in data.columns if c.startswith(\"Mnt\")]\n",
    "if mnt_cols:\n",
    "    data[\"TotalSpend\"] = data[mnt_cols].sum(axis=1)\n",
    "    kpi[\"CA_total_estime\"] = float(data[\"TotalSpend\"].sum())\n",
    "    kpi[\"CA_median_client\"] = float(data[\"TotalSpend\"].median())\n",
    "\n",
    "# Income median si dispo\n",
    "if \"Income\" in data.columns:\n",
    "    kpi[\"Revenu_median\"] = float(data[\"Income\"].median())\n",
    "\n",
    "# Taux d'acceptation par campagne + campagne récente\n",
    "for c in accepted_cols:\n",
    "    ser = pd.to_numeric(data[c], errors=\"coerce\")\n",
    "    if ser.notna().any():\n",
    "        kpi[f\"Taux_acceptation_{c}\"] = ser.mean()\n",
    "\n",
    "if response_col:\n",
    "    kpi[\"Taux_conversion_campagne_recente\"] = data[response_col].mean()\n",
    "\n",
    "pd.Series(kpi).to_frame(\"Valeur\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualisation simple de la distribution de la réponse récente (si dispo)\n",
    "if response_col:\n",
    "    counts = data[response_col].value_counts(dropna=False).sort_index()\n",
    "    plt.figure()\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.title(\"Distribution de la réponse récente (Response)\")\n",
    "    plt.xlabel(\"Response\")\n",
    "    plt.ylabel(\"Effectif\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6090b2",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering — variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0883c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "fe = data.copy()\n",
    "\n",
    "# Age\n",
    "if \"Year_Birth\" in fe.columns:\n",
    "    fe[\"Age\"] = datetime.now().year - fe[\"Year_Birth\"]\n",
    "\n",
    "# Enfants au foyer\n",
    "if set([\"Kidhome\",\"Teenhome\"]).issubset(fe.columns):\n",
    "    fe[\"KidsTotal\"] = fe[\"Kidhome\"] + fe[\"Teenhome\"]\n",
    "    fe[\"HasKids\"] = (fe[\"KidsTotal\"] > 0).astype(int)\n",
    "\n",
    "# Ancienneté client (si date dispo)\n",
    "if \"Dt_Customer\" in fe.columns:\n",
    "    fe[\"CustomerSeniority_days\"] = (pd.Timestamp.now().normalize() - fe[\"Dt_Customer\"]).dt.days\n",
    "\n",
    "# Agrégats monétaires\n",
    "mnt_cols = [c for c in fe.columns if c.startswith(\"Mnt\")]\n",
    "if mnt_cols:\n",
    "    fe[\"TotalSpend\"] = fe[mnt_cols].sum(axis=1)\n",
    "    fe[\"AvgBasket\"] = fe[\"TotalSpend\"] / (fe[\"TotalSpend\"]>0).replace({False: np.nan, True: 1})\n",
    "\n",
    "# Fréquence par canaux\n",
    "if set([\"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\"]).issubset(fe.columns):\n",
    "    fe[\"TotalPurchases\"] = fe[[\"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\"]].sum(axis=1)\n",
    "    for c in [\"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\"]:\n",
    "        fe[c.replace(\"Num\",\"Share_\")] = fe[c] / fe[\"TotalPurchases\"].replace(0, np.nan)\n",
    "\n",
    "# RFM proxy\n",
    "if \"Recency\" in fe.columns:\n",
    "    fe[\"R_recency\"] = fe[\"Recency\"]\n",
    "if \"TotalPurchases\" in fe.columns:\n",
    "    fe[\"F_frequency\"] = fe[\"TotalPurchases\"]\n",
    "if \"TotalSpend\" in fe.columns:\n",
    "    fe[\"M_monetary\"] = fe[\"TotalSpend\"]\n",
    "\n",
    "fe.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a5995",
   "metadata": {},
   "source": [
    "## 6. Diagnostics visuels (distributions, corrélations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c95063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Corrélations numériques\n",
    "num_cols = fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(num_cols) >= 2:\n",
    "    corr = fe[num_cols].corr(numeric_only=True)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(corr, interpolation=\"nearest\")\n",
    "    plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
    "    plt.yticks(range(len(num_cols)), num_cols)\n",
    "    plt.title(\"Matrice de corrélation (numérique)\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51a8b3",
   "metadata": {},
   "source": [
    "## 7. Segmentation client — Clustering (KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51535558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Choix des features de clustering (adapter selon le contexte)\n",
    "cluster_features = []\n",
    "for col in [\"R_recency\",\"F_frequency\",\"M_monetary\",\"Share_WebPurchases\",\"Share_CatalogPurchases\",\"Share_StorePurchases\",\"Age\",\"Income\",\"CustomerSeniority_days\"]:\n",
    "    if col in fe.columns:\n",
    "        cluster_features.append(col)\n",
    "\n",
    "X = fe[cluster_features].copy().fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Heuristique sur k (inertie, silhouette)\n",
    "inertias = []\n",
    "sils = []\n",
    "ks = list(range(2,8))\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    sils.append(sil)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ks, inertias, marker='o')\n",
    "plt.title(\"Elbow method (Inertie vs k)\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Inertie\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ks, sils, marker='o')\n",
    "plt.title(\"Silhouette vs k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fixer un k (ex: meilleur silhouette)\n",
    "best_k = ks[int(np.argmax(sils))]\n",
    "kmeans = KMeans(n_clusters=best_k, n_init=20, random_state=42)\n",
    "fe[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "fe.groupby(\"Cluster\")[cluster_features].median().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843106ea",
   "metadata": {},
   "source": [
    "## 8. Efficacité des campagnes par segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Taux d'acceptation par segment (campagnes historiques et récente)\n",
    "tab = {}\n",
    "accepted_cols = [c for c in fe.columns if c.lower().startswith(\"acceptedcmp\")]\n",
    "for c in accepted_cols + ([\"Response\"] if \"Response\" in fe.columns else []):\n",
    "    if c in fe.columns:\n",
    "        tab[c] = fe.groupby(\"Cluster\")[c].mean()\n",
    "\n",
    "camp_by_seg = pd.DataFrame(tab).sort_index()\n",
    "camp_by_seg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f574476",
   "metadata": {},
   "source": [
    "## 9. Modélisation — Prédire la réponse client (`Response`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "if \"Response\" in fe.columns:\n",
    "    y = fe[\"Response\"].fillna(0).astype(int)  # hypothèse: NaN -> non réponse\n",
    "    # Sélection de features (num + cat)\n",
    "    cat_cols = [c for c in fe.select_dtypes(include=[\"object\"]).columns if c not in [\"Dt_Customer\"]]\n",
    "    num_cols = [c for c in fe.select_dtypes(include=[np.number]).columns if c not in [\"Response\"]]\n",
    "\n",
    "    X = fe[cat_cols + num_cols].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    preproc = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ])\n",
    "\n",
    "    models = {\n",
    "        \"LogReg\": LogisticRegression(max_iter=200),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline([(\"pre\", preproc), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        proba = pipe.predict_proba(X_test)[:,1]\n",
    "        auc = metrics.roc_auc_score(y_test, proba)\n",
    "        pr_auc = metrics.average_precision_score(y_test, proba)\n",
    "        results[name] = {\"ROC_AUC\": auc, \"PR_AUC\": pr_auc, \"pipeline\": pipe, \"proba\": proba, \"y_test\": y_test}\n",
    "\n",
    "    pd.DataFrame({k: {m: v[m] for m in [\"ROC_AUC\",\"PR_AUC\"]} for k,v in results.items()})\n",
    "else:\n",
    "    print(\"Aucune colonne 'Response' trouvée — la modélisation de propension est sautée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Courbes ROC & PR pour le meilleur modèle (selon PR_AUC)\n",
    "if \"Response\" in fe.columns:\n",
    "    best_name = max(results, key=lambda k: results[k][\"PR_AUC\"])\n",
    "    best = results[best_name]\n",
    "    proba = best[\"proba\"]\n",
    "    y_true = best[\"y_test\"]\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_true, proba)\n",
    "    prec, rec, _ = metrics.precision_recall_curve(y_true, proba)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "    plt.title(f\"ROC — {best_name}\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec)\n",
    "    plt.title(f\"Precision-Recall — {best_name}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Décile lift\n",
    "    import pandas as pd\n",
    "    deciles = pd.qcut(proba, 10, labels=False, duplicates=\"drop\")\n",
    "    lift_table = pd.DataFrame({\"decile\": deciles, \"y\": y_true}).groupby(\"decile\")[\"y\"].mean().sort_index(ascending=False)\n",
    "    lift_table.index = lift_table.index + 1  # deciles 1..10\n",
    "    lift_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b92a4",
   "metadata": {},
   "source": [
    "## 10. Explicabilité (importance des variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importance brute pour RandomForest (sur variables numériques post-encodage, proxy)\n",
    "if \"Response\" in fe.columns:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    best_name = \"RandomForest\"\n",
    "    if best_name in results:\n",
    "        best_pipe = results[best_name][\"pipeline\"]\n",
    "        X_test = fe[[c for c in fe.columns if c not in [\"Response\"]]].iloc[results[best_name][\"y_test\"].index]\n",
    "        y_test = results[best_name][\"y_test\"]\n",
    "        r = permutation_importance(best_pipe, X_test, y_test, n_repeats=5, random_state=42, scoring=\"roc_auc\")\n",
    "        imp = pd.Series(r.importances_mean, index=[f\"f{i}\" for i in range(len(r.importances_mean))]).sort_values(ascending=False).head(20)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        imp[::-1].plot(kind=\"barh\")\n",
    "        plt.title(\"Top 20 importances — Permutation importance (proxy)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d986532",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Recommandations métier (à compléter après lecture des résultats)\n",
    "- Ciblage prioritaire : segments/clusters avec meilleur taux de réponse ou meilleure valeur `M`.\n",
    "- Canal d’activation recommandé : selon parts d’achats `Share_*` et performance par segment.\n",
    "- Pression marketing : ajuster selon `Recency` et `NumWebVisitsMonth` pour éviter la sur-sollicitation.\n",
    "- Offre personnalisée : catégories `Mnt*` dominantes par segment.\n",
    "- Suivi des KPIs : taux d’acceptation, **PR AUC** du modèle, **lift décile 1**, ROI (si `Z_CostContact`/`Z_Revenue`).\n",
    "\n",
    "> Pendant la soutenance : partir des KPIs → insights segment → modèle → plan d’action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9d707",
   "metadata": {},
   "source": [
    "## 12. Annexes — fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc76b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def top_decile_lift(y_true, proba):\n",
    "    import numpy as np\n",
    "    order = np.argsort(-proba)\n",
    "    n = max(1, int(0.1 * len(y_true)))\n",
    "    top_idx = order[:n]\n",
    "    rate_top = y_true.iloc[top_idx].mean()\n",
    "    rate_all = y_true.mean()\n",
    "    return rate_top / rate_all if rate_all > 0 else np.nan\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
